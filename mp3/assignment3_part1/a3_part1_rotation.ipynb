{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWMWW8Ab_345"
      },
      "source": [
        "# (Optional) Colab Setup\n",
        "If you aren't using Colab, you can delete the following code cell. This is just to help students with mounting to Google Drive to access the other .py files and downloading the data, which is a little trickier on Colab than on your local machine using Jupyter. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH4wc4iD_6w_",
        "outputId": "56e7be1a-7822-4942-a946-9e6daf643024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# you will be prompted with a window asking to grant permissions\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpNsPHZc_879",
        "outputId": "148bad11-150b-4414-cdc0-05b0192ae056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS444/assignment3\n"
          ]
        }
      ],
      "source": [
        "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
        "import os\n",
        "datadir = \"/content/assignment3\"\n",
        "if not os.path.exists(datadir):\n",
        "  !ln -s \"/content/drive/MyDrive/CS444/assignment3/\" $datadir # TODO: Fill your A3 path\n",
        "os.chdir(datadir)\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5DJvBwb6xT"
      },
      "source": [
        "#Data Setup\n",
        "\n",
        "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
        "\n",
        "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHkeNUOKiFbP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "def rotate_img(img, rot):\n",
        "    if rot == 0: # 0 degrees rotation\n",
        "        return img\n",
        "    elif rot==1:\n",
        "      return TF.rotate(img, 90)\n",
        "    elif rot==2:\n",
        "      return TF.rotate(img, 180)\n",
        "    elif rot==3:\n",
        "      return TF.rotate(img, 270)    \n",
        "    else:\n",
        "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
        "\n",
        "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
        "\n",
        "    def __init__(self, root, train, download, transform) -> None:\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index: int):\n",
        "        image, cls_label = super().__getitem__(index)\n",
        "\n",
        "        # randomly select image rotation\n",
        "        rotation_label = random.choice([0, 1, 2, 3])\n",
        "        image_rotated = rotate_img(image, rotation_label)\n",
        "\n",
        "        rotation_label = torch.tensor(rotation_label).long()\n",
        "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCBSpNWpb8uw",
        "outputId": "408dd9ad-588f-4126-f5de-4f200fe7e6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = CIFAR10Rotation(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR10Rotation(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCWMyGhVOJB"
      },
      "source": [
        "Show some example images and rotated images with labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "A9wN4BJWVMzB",
        "outputId": "bc349c02-5544-4aab-ae99-68c2a3a8591f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels:  car   car   plane deer \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rotation labels:  0     270   270   90   \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "rot_classes = ('0', '90', '180', '270')\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    # unnormalize\n",
        "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img) #Whitening the input image,it reduces the effect of variations in brightness and contrast between images.\n",
        "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img) #rescaling the pixel values back to their original range of [0, 255]\n",
        "    #These values correspond to the mean and standard deviation of the CIFAR-10 dataset, and are used to \n",
        "    #normalize the pixel values so that they have a mean of 0 and a standard deviation of 1.\n",
        "    npimg = img.numpy() #converts the image tensor to a NumPy array \n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  #transposes the dimensions so that the image is in the format (height, width, channels) instead of the PyTorch format (channels, height, width)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, rot_images, rot_labels, labels = next(dataiter)\n",
        "\n",
        "# print images and rotated images\n",
        "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
        "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
        "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unCucbHexG4W"
      },
      "source": [
        "#Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pptQRpqK0rOl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_test(net, testloader, criterion, task):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    avg_test_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for images, images_rotated, labels, cls_labels in testloader:\n",
        "            if task == 'rotation':\n",
        "              images, labels = images_rotated.to(device), labels.to(device)\n",
        "            elif task == 'classification':\n",
        "              images, labels = images.to(device), cls_labels.to(device)\n",
        "            # TODO: Calculate outputs by running images through the network\n",
        "            # The class with the highest energy is what we choose as prediction\n",
        "            outputs=net(images)\n",
        "            _,predicted=torch.max(outputs.data,1)\n",
        "            total+=labels.size(0)\n",
        "            correct+=(predicted==labels).sum().item()\n",
        "            # loss\n",
        "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
        "    print('TESTING:')\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf698c16A9k5"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYdnb1Wsta_"
      },
      "source": [
        "#Train a ResNet18 on the rotation task\n",
        "\n",
        "In this section, we will train a ResNet18 model on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "knAiwdURvBHk",
        "outputId": "f545bba0-741c-4338-9076-c35fb61c375e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "235MEIUgsv65"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "net = resnet18(num_classes=4)\n",
        "net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vuhiw0ZoszAd"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = None\n",
        "optimizer = None\n",
        "\n",
        "# TODO: Define criterion and optimizer\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters(),lr=0.001)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw0vTPhWsBoQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_test(net, testloader, criterion, task):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    avg_test_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for images, images_rotated, labels, cls_labels in testloader:\n",
        "            if task == 'rotation':\n",
        "              images, labels = images_rotated.to(device), labels.to(device)\n",
        "            elif task == 'classification':\n",
        "              images, labels = images.to(device), cls_labels.to(device)\n",
        "            # TODO: Calculate outputs by running images through the network\n",
        "            # The class with the highest energy is what we choose as prediction\n",
        "            outputs=net(images)\n",
        "            _,predicted=torch.max(outputs.data,1)\n",
        "            total+=labels.size(0)\n",
        "            correct+=(predicted==labels).sum().item()\n",
        "            # loss\n",
        "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
        "    print('TESTING:')\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WleH-YBgs0rq"
      },
      "outputs": [],
      "source": [
        "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
        "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
        "\n",
        "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        running_total = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        net.train()\n",
        "\n",
        "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
        "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
        "\n",
        "            # TODO: Set the data to the correct device; Different task will use different inputs and labels                      \n",
        "            if task==\"rotation\":\n",
        "              imgs=imgs_rotated.to(device)\n",
        "              labels=rotation_label.to(device)\n",
        "            elif task=='classification':\n",
        "              imgs=imgs.to(device)  \n",
        "              labels=cls_label.to(device)\n",
        "\n",
        "            # TODO: Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # TODO: forward + backward + optimize\n",
        "            outputs=net(imgs)\n",
        "            loss=criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # TODO: Get predicted results\n",
        "            _,predicted = torch.max(outputs.data,1)\n",
        "\n",
        "            # print statistics\n",
        "            print_freq = 100\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # calc acc\n",
        "            running_total += labels.size(0)\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
        "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
        "                start_time = time.time()\n",
        "\n",
        "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.\n",
        "        net.eval()\n",
        "        run_test(net,testloader,criterion,task)\n",
        "        \n",
        "\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u4AsfAKtaQS",
        "outputId": "fe5513fe-e2de-4b70-b172-9bed6dd15d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.058 acc: 54.22 time: 8.80\n",
            "[1,   200] loss: 1.043 acc: 55.50 time: 10.20\n",
            "[1,   300] loss: 1.014 acc: 56.45 time: 10.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.24 %\n",
            "Average loss on the 10000 test images: 0.980\n",
            "[2,   100] loss: 0.986 acc: 58.51 time: 9.10\n",
            "[2,   200] loss: 0.972 acc: 59.05 time: 10.06\n",
            "[2,   300] loss: 0.976 acc: 59.53 time: 10.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.24 %\n",
            "Average loss on the 10000 test images: 1.011\n",
            "[3,   100] loss: 0.958 acc: 59.74 time: 9.17\n",
            "[3,   200] loss: 0.938 acc: 60.61 time: 10.21\n",
            "[3,   300] loss: 0.934 acc: 61.07 time: 10.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.58 %\n",
            "Average loss on the 10000 test images: 0.896\n",
            "[4,   100] loss: 0.924 acc: 61.58 time: 8.95\n",
            "[4,   200] loss: 0.900 acc: 62.06 time: 10.27\n",
            "[4,   300] loss: 0.896 acc: 62.77 time: 10.20\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.40 %\n",
            "Average loss on the 10000 test images: 0.885\n",
            "[5,   100] loss: 0.893 acc: 62.47 time: 8.82\n",
            "[5,   200] loss: 0.861 acc: 64.61 time: 10.32\n",
            "[5,   300] loss: 0.884 acc: 63.58 time: 10.39\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 65.08 %\n",
            "Average loss on the 10000 test images: 0.837\n",
            "[6,   100] loss: 0.863 acc: 64.09 time: 8.78\n",
            "[6,   200] loss: 0.852 acc: 64.86 time: 10.42\n",
            "[6,   300] loss: 0.856 acc: 64.64 time: 10.40\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.99 %\n",
            "Average loss on the 10000 test images: 0.844\n",
            "[7,   100] loss: 0.844 acc: 64.97 time: 8.73\n",
            "[7,   200] loss: 0.841 acc: 65.77 time: 12.37\n",
            "[7,   300] loss: 0.824 acc: 66.09 time: 10.28\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 65.51 %\n",
            "Average loss on the 10000 test images: 0.836\n",
            "[8,   100] loss: 0.825 acc: 66.01 time: 9.11\n",
            "[8,   200] loss: 0.817 acc: 66.25 time: 10.34\n",
            "[8,   300] loss: 0.802 acc: 67.73 time: 9.83\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.32 %\n",
            "Average loss on the 10000 test images: 0.784\n",
            "[9,   100] loss: 0.806 acc: 67.22 time: 9.30\n",
            "[9,   200] loss: 0.806 acc: 67.20 time: 10.16\n",
            "[9,   300] loss: 0.785 acc: 67.99 time: 9.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.82 %\n",
            "Average loss on the 10000 test images: 0.794\n",
            "[10,   100] loss: 0.789 acc: 68.00 time: 9.73\n",
            "[10,   200] loss: 0.777 acc: 68.71 time: 10.39\n",
            "[10,   300] loss: 0.789 acc: 67.83 time: 9.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.42 %\n",
            "Average loss on the 10000 test images: 0.752\n",
            "[11,   100] loss: 0.769 acc: 68.84 time: 10.06\n",
            "[11,   200] loss: 0.764 acc: 69.38 time: 10.31\n",
            "[11,   300] loss: 0.764 acc: 68.94 time: 9.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.85 %\n",
            "Average loss on the 10000 test images: 0.749\n",
            "[12,   100] loss: 0.740 acc: 70.64 time: 9.42\n",
            "[12,   200] loss: 0.731 acc: 70.48 time: 10.45\n",
            "[12,   300] loss: 0.753 acc: 69.37 time: 10.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.70 %\n",
            "Average loss on the 10000 test images: 0.726\n",
            "[13,   100] loss: 0.731 acc: 70.44 time: 9.58\n",
            "[13,   200] loss: 0.723 acc: 71.30 time: 10.67\n",
            "[13,   300] loss: 0.718 acc: 71.54 time: 10.47\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.99 %\n",
            "Average loss on the 10000 test images: 0.712\n",
            "[14,   100] loss: 0.710 acc: 71.48 time: 9.33\n",
            "[14,   200] loss: 0.713 acc: 71.23 time: 10.61\n",
            "[14,   300] loss: 0.714 acc: 71.61 time: 10.45\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.82 %\n",
            "Average loss on the 10000 test images: 0.706\n",
            "[15,   100] loss: 0.703 acc: 71.96 time: 9.31\n",
            "[15,   200] loss: 0.698 acc: 72.08 time: 10.47\n",
            "[15,   300] loss: 0.696 acc: 72.12 time: 10.38\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.77 %\n",
            "Average loss on the 10000 test images: 0.767\n",
            "[16,   100] loss: 0.659 acc: 74.04 time: 9.35\n",
            "[16,   200] loss: 0.625 acc: 75.34 time: 12.74\n",
            "[16,   300] loss: 0.621 acc: 75.83 time: 9.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.63 %\n",
            "Average loss on the 10000 test images: 0.597\n",
            "[17,   100] loss: 0.606 acc: 76.07 time: 10.30\n",
            "[17,   200] loss: 0.614 acc: 75.67 time: 10.59\n",
            "[17,   300] loss: 0.617 acc: 75.85 time: 9.34\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.88 %\n",
            "Average loss on the 10000 test images: 0.585\n",
            "[18,   100] loss: 0.606 acc: 76.09 time: 10.27\n",
            "[18,   200] loss: 0.597 acc: 76.39 time: 10.36\n",
            "[18,   300] loss: 0.602 acc: 76.75 time: 9.59\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.27 %\n",
            "Average loss on the 10000 test images: 0.579\n",
            "[19,   100] loss: 0.598 acc: 76.36 time: 10.23\n",
            "[19,   200] loss: 0.599 acc: 76.55 time: 10.48\n",
            "[19,   300] loss: 0.586 acc: 76.53 time: 9.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.68 %\n",
            "Average loss on the 10000 test images: 0.576\n",
            "[20,   100] loss: 0.596 acc: 76.74 time: 10.60\n",
            "[20,   200] loss: 0.596 acc: 76.76 time: 10.48\n",
            "[20,   300] loss: 0.573 acc: 77.79 time: 8.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.93 %\n",
            "Average loss on the 10000 test images: 0.580\n",
            "[21,   100] loss: 0.573 acc: 77.52 time: 10.63\n",
            "[21,   200] loss: 0.586 acc: 77.20 time: 10.53\n",
            "[21,   300] loss: 0.584 acc: 77.20 time: 8.47\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.64 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[22,   100] loss: 0.577 acc: 77.30 time: 10.61\n",
            "[22,   200] loss: 0.588 acc: 76.80 time: 10.36\n",
            "[22,   300] loss: 0.564 acc: 77.91 time: 8.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.68 %\n",
            "Average loss on the 10000 test images: 0.561\n",
            "[23,   100] loss: 0.571 acc: 77.91 time: 10.70\n",
            "[23,   200] loss: 0.575 acc: 77.57 time: 10.39\n",
            "[23,   300] loss: 0.568 acc: 77.75 time: 8.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.41 %\n",
            "Average loss on the 10000 test images: 0.553\n",
            "[24,   100] loss: 0.565 acc: 77.88 time: 10.56\n",
            "[24,   200] loss: 0.567 acc: 78.04 time: 10.31\n",
            "[24,   300] loss: 0.568 acc: 78.02 time: 8.59\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.65 %\n",
            "Average loss on the 10000 test images: 0.565\n",
            "[25,   100] loss: 0.567 acc: 78.33 time: 10.97\n",
            "[25,   200] loss: 0.575 acc: 77.27 time: 11.77\n",
            "[25,   300] loss: 0.560 acc: 78.26 time: 8.66\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.01 %\n",
            "Average loss on the 10000 test images: 0.560\n",
            "[26,   100] loss: 0.562 acc: 78.03 time: 10.62\n",
            "[26,   200] loss: 0.568 acc: 77.90 time: 10.44\n",
            "[26,   300] loss: 0.549 acc: 78.52 time: 8.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.25 %\n",
            "Average loss on the 10000 test images: 0.544\n",
            "[27,   100] loss: 0.554 acc: 78.65 time: 10.51\n",
            "[27,   200] loss: 0.551 acc: 78.56 time: 10.43\n",
            "[27,   300] loss: 0.555 acc: 78.55 time: 8.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.59 %\n",
            "Average loss on the 10000 test images: 0.547\n",
            "[28,   100] loss: 0.548 acc: 78.47 time: 10.56\n",
            "[28,   200] loss: 0.552 acc: 78.70 time: 10.22\n",
            "[28,   300] loss: 0.561 acc: 77.67 time: 8.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.03 %\n",
            "Average loss on the 10000 test images: 0.545\n",
            "[29,   100] loss: 0.553 acc: 78.49 time: 10.76\n",
            "[29,   200] loss: 0.552 acc: 78.53 time: 9.72\n",
            "[29,   300] loss: 0.549 acc: 78.78 time: 9.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.21 %\n",
            "Average loss on the 10000 test images: 0.542\n",
            "[30,   100] loss: 0.546 acc: 78.48 time: 10.59\n",
            "[30,   200] loss: 0.534 acc: 79.77 time: 8.59\n",
            "[30,   300] loss: 0.548 acc: 79.03 time: 10.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.60 %\n",
            "Average loss on the 10000 test images: 0.547\n",
            "[31,   100] loss: 0.544 acc: 78.60 time: 10.48\n",
            "[31,   200] loss: 0.541 acc: 78.80 time: 8.51\n",
            "[31,   300] loss: 0.537 acc: 79.12 time: 10.35\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.33 %\n",
            "Average loss on the 10000 test images: 0.537\n",
            "[32,   100] loss: 0.531 acc: 79.66 time: 10.33\n",
            "[32,   200] loss: 0.533 acc: 79.23 time: 8.53\n",
            "[32,   300] loss: 0.543 acc: 78.59 time: 10.38\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.09 %\n",
            "Average loss on the 10000 test images: 0.531\n",
            "[33,   100] loss: 0.523 acc: 80.05 time: 9.79\n",
            "[33,   200] loss: 0.532 acc: 79.39 time: 9.24\n",
            "[33,   300] loss: 0.536 acc: 79.27 time: 10.34\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.94 %\n",
            "Average loss on the 10000 test images: 0.536\n",
            "[34,   100] loss: 0.544 acc: 78.71 time: 9.63\n",
            "[34,   200] loss: 0.528 acc: 79.28 time: 11.50\n",
            "[34,   300] loss: 0.534 acc: 79.43 time: 10.25\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.54 %\n",
            "Average loss on the 10000 test images: 0.532\n",
            "[35,   100] loss: 0.533 acc: 79.56 time: 9.41\n",
            "[35,   200] loss: 0.520 acc: 79.57 time: 9.34\n",
            "[35,   300] loss: 0.532 acc: 79.52 time: 10.14\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.39 %\n",
            "Average loss on the 10000 test images: 0.528\n",
            "[36,   100] loss: 0.532 acc: 79.08 time: 9.00\n",
            "[36,   200] loss: 0.543 acc: 78.93 time: 10.13\n",
            "[36,   300] loss: 0.527 acc: 79.40 time: 10.51\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.14 %\n",
            "Average loss on the 10000 test images: 0.528\n",
            "[37,   100] loss: 0.537 acc: 79.21 time: 8.32\n",
            "[37,   200] loss: 0.518 acc: 79.95 time: 10.25\n",
            "[37,   300] loss: 0.531 acc: 79.34 time: 10.29\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.38 %\n",
            "Average loss on the 10000 test images: 0.531\n",
            "[38,   100] loss: 0.535 acc: 79.00 time: 8.64\n",
            "[38,   200] loss: 0.526 acc: 79.71 time: 10.24\n",
            "[38,   300] loss: 0.534 acc: 79.04 time: 10.18\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.90 %\n",
            "Average loss on the 10000 test images: 0.531\n",
            "[39,   100] loss: 0.516 acc: 79.55 time: 8.68\n",
            "[39,   200] loss: 0.522 acc: 79.65 time: 10.41\n",
            "[39,   300] loss: 0.534 acc: 79.41 time: 10.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.01 %\n",
            "Average loss on the 10000 test images: 0.529\n",
            "[40,   100] loss: 0.526 acc: 79.23 time: 8.77\n",
            "[40,   200] loss: 0.535 acc: 79.20 time: 10.43\n",
            "[40,   300] loss: 0.528 acc: 79.51 time: 10.42\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.49 %\n",
            "Average loss on the 10000 test images: 0.525\n",
            "[41,   100] loss: 0.533 acc: 79.10 time: 8.87\n",
            "[41,   200] loss: 0.524 acc: 79.50 time: 10.44\n",
            "[41,   300] loss: 0.532 acc: 78.96 time: 10.44\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.21 %\n",
            "Average loss on the 10000 test images: 0.529\n",
            "[42,   100] loss: 0.537 acc: 78.97 time: 8.83\n",
            "[42,   200] loss: 0.518 acc: 79.88 time: 10.53\n",
            "[42,   300] loss: 0.539 acc: 79.11 time: 10.38\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.33 %\n",
            "Average loss on the 10000 test images: 0.521\n",
            "[43,   100] loss: 0.529 acc: 79.83 time: 11.08\n",
            "[43,   200] loss: 0.515 acc: 80.12 time: 10.54\n",
            "[43,   300] loss: 0.528 acc: 79.49 time: 10.46\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.35 %\n",
            "Average loss on the 10000 test images: 0.521\n",
            "[44,   100] loss: 0.522 acc: 79.71 time: 8.85\n",
            "[44,   200] loss: 0.518 acc: 79.64 time: 10.59\n",
            "[44,   300] loss: 0.523 acc: 79.76 time: 10.49\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.98 %\n",
            "Average loss on the 10000 test images: 0.528\n",
            "[45,   100] loss: 0.526 acc: 79.13 time: 9.07\n",
            "[45,   200] loss: 0.523 acc: 79.94 time: 10.52\n",
            "[45,   300] loss: 0.524 acc: 79.84 time: 10.73\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.04 %\n",
            "Average loss on the 10000 test images: 0.527\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n",
        "\n",
        "# TODO: Save the model\n",
        "torch.save(net.state_dict(), 'my_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLMRTS9rTnk"
      },
      "source": [
        "##Fine-tuning on the pre-trained model\n",
        "\n",
        "In this section, we will load the pre-trained ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4nX4ExlrymI",
        "outputId": "db8461f2-4761-4d39-cc15-81f6a74c0722"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# TODO: Load the pre-trained ResNet18 model\n",
        "model_path = 'my_model.pt'\n",
        "net = resnet18()\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 4)\n",
        "net.load_state_dict(torch.load(model_path))\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 10)\n",
        "# Define the device (GPU or CPU) to use\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD44g-TxwYdU"
      },
      "outputs": [],
      "source": [
        "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable\n",
        "# Freeze all previous layers\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the 'layer4' block and 'fc' layer\n",
        "for param in net.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in net.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# for name, param in net.named_parameters():\n",
        "#     if 'layer4' in name or 'fc' in name:  # If the parameter belongs to the 'layer4' block or 'fc' layer\n",
        "#         param.requires_grad = True  # Set requires_grad to True\n",
        "#     else:\n",
        "#         param.requires_grad = False    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T5DX0efr4fh",
        "outputId": "8edf7836-97fe-4529-bd92-9874be6940e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb032dG700ph"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vLSwOo6sBjl",
        "outputId": "30d9da69-cd75-40de-84cc-89b2607c6875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.771 acc: 33.41 time: 11.10\n",
            "[1,   200] loss: 1.449 acc: 47.12 time: 6.94\n",
            "[1,   300] loss: 1.392 acc: 49.17 time: 8.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 52.57 %\n",
            "Average loss on the 10000 test images: 1.320\n",
            "[2,   100] loss: 1.331 acc: 51.44 time: 8.28\n",
            "[2,   200] loss: 1.312 acc: 51.98 time: 8.40\n",
            "[2,   300] loss: 1.334 acc: 51.93 time: 8.29\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 53.71 %\n",
            "Average loss on the 10000 test images: 1.276\n",
            "[3,   100] loss: 1.292 acc: 52.86 time: 8.82\n",
            "[3,   200] loss: 1.293 acc: 53.69 time: 8.17\n",
            "[3,   300] loss: 1.275 acc: 53.34 time: 7.65\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 54.80 %\n",
            "Average loss on the 10000 test images: 1.248\n",
            "[4,   100] loss: 1.253 acc: 54.20 time: 8.11\n",
            "[4,   200] loss: 1.250 acc: 54.30 time: 8.02\n",
            "[4,   300] loss: 1.255 acc: 54.27 time: 8.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 56.67 %\n",
            "Average loss on the 10000 test images: 1.213\n",
            "[5,   100] loss: 1.247 acc: 54.55 time: 8.14\n",
            "[5,   200] loss: 1.240 acc: 55.42 time: 8.74\n",
            "[5,   300] loss: 1.235 acc: 55.01 time: 7.20\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 57.31 %\n",
            "Average loss on the 10000 test images: 1.173\n",
            "[6,   100] loss: 1.231 acc: 55.23 time: 8.92\n",
            "[6,   200] loss: 1.218 acc: 55.90 time: 7.07\n",
            "[6,   300] loss: 1.220 acc: 55.82 time: 8.64\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.30 %\n",
            "Average loss on the 10000 test images: 1.182\n",
            "[7,   100] loss: 1.194 acc: 56.57 time: 7.13\n",
            "[7,   200] loss: 1.214 acc: 56.02 time: 8.49\n",
            "[7,   300] loss: 1.204 acc: 56.41 time: 7.08\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.50 %\n",
            "Average loss on the 10000 test images: 1.165\n",
            "[8,   100] loss: 1.181 acc: 57.17 time: 10.27\n",
            "[8,   200] loss: 1.201 acc: 56.62 time: 8.03\n",
            "[8,   300] loss: 1.204 acc: 56.66 time: 7.67\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 60.04 %\n",
            "Average loss on the 10000 test images: 1.127\n",
            "[9,   100] loss: 1.181 acc: 56.99 time: 8.30\n",
            "[9,   200] loss: 1.170 acc: 57.54 time: 7.98\n",
            "[9,   300] loss: 1.194 acc: 57.09 time: 8.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 59.53 %\n",
            "Average loss on the 10000 test images: 1.139\n",
            "[10,   100] loss: 1.161 acc: 58.56 time: 8.24\n",
            "[10,   200] loss: 1.162 acc: 57.99 time: 8.65\n",
            "[10,   300] loss: 1.186 acc: 57.53 time: 6.89\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 59.86 %\n",
            "Average loss on the 10000 test images: 1.131\n",
            "[11,   100] loss: 1.149 acc: 58.49 time: 9.03\n",
            "[11,   200] loss: 1.116 acc: 59.95 time: 7.01\n",
            "[11,   300] loss: 1.096 acc: 60.58 time: 8.57\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.81 %\n",
            "Average loss on the 10000 test images: 1.079\n",
            "[12,   100] loss: 1.105 acc: 59.79 time: 7.31\n",
            "[12,   200] loss: 1.100 acc: 60.05 time: 8.83\n",
            "[12,   300] loss: 1.122 acc: 59.54 time: 7.19\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.63 %\n",
            "Average loss on the 10000 test images: 1.083\n",
            "[13,   100] loss: 1.111 acc: 59.81 time: 8.84\n",
            "[13,   200] loss: 1.096 acc: 60.56 time: 7.08\n",
            "[13,   300] loss: 1.088 acc: 60.81 time: 8.76\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.74 %\n",
            "Average loss on the 10000 test images: 1.071\n",
            "[14,   100] loss: 1.075 acc: 60.98 time: 7.29\n",
            "[14,   200] loss: 1.101 acc: 60.32 time: 8.70\n",
            "[14,   300] loss: 1.085 acc: 60.65 time: 7.23\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.36 %\n",
            "Average loss on the 10000 test images: 1.060\n",
            "[15,   100] loss: 1.098 acc: 60.40 time: 8.93\n",
            "[15,   200] loss: 1.085 acc: 60.38 time: 6.93\n",
            "[15,   300] loss: 1.081 acc: 60.62 time: 8.67\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.35 %\n",
            "Average loss on the 10000 test images: 1.064\n",
            "[16,   100] loss: 1.075 acc: 61.09 time: 7.19\n",
            "[16,   200] loss: 1.088 acc: 60.64 time: 8.55\n",
            "[16,   300] loss: 1.101 acc: 60.41 time: 7.27\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.62 %\n",
            "Average loss on the 10000 test images: 1.056\n",
            "[17,   100] loss: 1.083 acc: 60.95 time: 8.76\n",
            "[17,   200] loss: 1.090 acc: 60.95 time: 6.94\n",
            "[17,   300] loss: 1.093 acc: 60.64 time: 8.70\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.34 %\n",
            "Average loss on the 10000 test images: 1.062\n",
            "[18,   100] loss: 1.079 acc: 61.08 time: 7.31\n",
            "[18,   200] loss: 1.087 acc: 60.66 time: 8.35\n",
            "[18,   300] loss: 1.078 acc: 61.03 time: 10.42\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.33 %\n",
            "Average loss on the 10000 test images: 1.061\n",
            "[19,   100] loss: 1.071 acc: 61.38 time: 8.24\n",
            "[19,   200] loss: 1.086 acc: 60.89 time: 8.91\n",
            "[19,   300] loss: 1.070 acc: 61.48 time: 7.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.69 %\n",
            "Average loss on the 10000 test images: 1.063\n",
            "[20,   100] loss: 1.088 acc: 60.62 time: 9.51\n",
            "[20,   200] loss: 1.073 acc: 61.42 time: 7.37\n",
            "[20,   300] loss: 1.073 acc: 60.54 time: 9.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.86 %\n",
            "Average loss on the 10000 test images: 1.055\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPNhcJBrcNj"
      },
      "source": [
        "## Fine-tuning on the randomly initialized model\n",
        "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RfXAh9vxXRB",
        "outputId": "e0cde1cd-d169-41c6-8624-7caa343a61f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# TODO: Randomly initialize a ResNet18 model\n",
        "net = resnet18(pretrained=False)\n",
        "num_classes = 10\n",
        "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpx-SYAizt4p"
      },
      "outputs": [],
      "source": [
        "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable\n",
        "# To do this, you should set requires_grad=False for the frozen layers.\n",
        "for name, param in net.named_parameters():\n",
        "    if 'layer4' not in name and 'fc' not in name:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUFWizbHxgm2",
        "outputId": "afa6033b-ccab-41be-d93c-dfbcb0b49727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxFrGj091AN_"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzRVy0MZxpoL",
        "outputId": "499e6deb-3bee-42e2-9329-5506c29aabea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.275 acc: 24.27 time: 8.86\n",
            "[1,   200] loss: 1.976 acc: 29.36 time: 9.30\n",
            "[1,   300] loss: 1.895 acc: 31.57 time: 9.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 35.71 %\n",
            "Average loss on the 10000 test images: 1.765\n",
            "[2,   100] loss: 1.837 acc: 33.45 time: 8.82\n",
            "[2,   200] loss: 1.820 acc: 34.26 time: 9.59\n",
            "[2,   300] loss: 1.792 acc: 34.98 time: 12.13\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 38.65 %\n",
            "Average loss on the 10000 test images: 1.704\n",
            "[3,   100] loss: 1.790 acc: 35.38 time: 8.95\n",
            "[3,   200] loss: 1.757 acc: 35.97 time: 9.72\n",
            "[3,   300] loss: 1.774 acc: 36.08 time: 7.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 38.62 %\n",
            "Average loss on the 10000 test images: 1.688\n",
            "[4,   100] loss: 1.753 acc: 36.48 time: 10.07\n",
            "[4,   200] loss: 1.752 acc: 36.67 time: 9.18\n",
            "[4,   300] loss: 1.736 acc: 36.49 time: 9.14\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 39.85 %\n",
            "Average loss on the 10000 test images: 1.667\n",
            "[5,   100] loss: 1.735 acc: 37.70 time: 10.19\n",
            "[5,   200] loss: 1.722 acc: 38.20 time: 9.48\n",
            "[5,   300] loss: 1.721 acc: 37.77 time: 9.45\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 40.76 %\n",
            "Average loss on the 10000 test images: 1.649\n",
            "[6,   100] loss: 1.699 acc: 38.73 time: 7.85\n",
            "[6,   200] loss: 1.712 acc: 38.12 time: 9.59\n",
            "[6,   300] loss: 1.724 acc: 37.96 time: 7.60\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.05 %\n",
            "Average loss on the 10000 test images: 1.637\n",
            "[7,   100] loss: 1.707 acc: 38.22 time: 9.91\n",
            "[7,   200] loss: 1.693 acc: 39.37 time: 8.66\n",
            "[7,   300] loss: 1.685 acc: 39.04 time: 8.39\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.53 %\n",
            "Average loss on the 10000 test images: 1.628\n",
            "[8,   100] loss: 1.685 acc: 39.50 time: 9.64\n",
            "[8,   200] loss: 1.697 acc: 38.08 time: 7.37\n",
            "[8,   300] loss: 1.691 acc: 39.32 time: 9.51\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.41 %\n",
            "Average loss on the 10000 test images: 1.630\n",
            "[9,   100] loss: 1.694 acc: 39.56 time: 7.69\n",
            "[9,   200] loss: 1.698 acc: 39.20 time: 9.37\n",
            "[9,   300] loss: 1.681 acc: 40.05 time: 8.12\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.30 %\n",
            "Average loss on the 10000 test images: 1.603\n",
            "[10,   100] loss: 1.673 acc: 39.89 time: 11.75\n",
            "[10,   200] loss: 1.667 acc: 39.66 time: 9.18\n",
            "[10,   300] loss: 1.662 acc: 40.40 time: 7.68\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.64 %\n",
            "Average loss on the 10000 test images: 1.622\n",
            "[11,   100] loss: 1.664 acc: 40.14 time: 9.69\n",
            "[11,   200] loss: 1.636 acc: 41.39 time: 7.49\n",
            "[11,   300] loss: 1.632 acc: 41.67 time: 9.62\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.05 %\n",
            "Average loss on the 10000 test images: 1.571\n",
            "[12,   100] loss: 1.612 acc: 42.08 time: 8.13\n",
            "[12,   200] loss: 1.616 acc: 41.67 time: 9.10\n",
            "[12,   300] loss: 1.603 acc: 42.40 time: 9.47\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.99 %\n",
            "Average loss on the 10000 test images: 1.560\n",
            "[13,   100] loss: 1.600 acc: 42.90 time: 8.35\n",
            "[13,   200] loss: 1.604 acc: 42.51 time: 9.38\n",
            "[13,   300] loss: 1.597 acc: 42.69 time: 7.57\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.30 %\n",
            "Average loss on the 10000 test images: 1.561\n",
            "[14,   100] loss: 1.582 acc: 43.08 time: 9.61\n",
            "[14,   200] loss: 1.595 acc: 42.78 time: 7.49\n",
            "[14,   300] loss: 1.602 acc: 42.11 time: 9.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.90 %\n",
            "Average loss on the 10000 test images: 1.553\n",
            "[15,   100] loss: 1.580 acc: 42.57 time: 10.81\n",
            "[15,   200] loss: 1.581 acc: 43.14 time: 7.55\n",
            "[15,   300] loss: 1.574 acc: 43.46 time: 8.92\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.85 %\n",
            "Average loss on the 10000 test images: 1.548\n",
            "[16,   100] loss: 1.572 acc: 43.83 time: 8.47\n",
            "[16,   200] loss: 1.577 acc: 43.55 time: 8.33\n",
            "[16,   300] loss: 1.585 acc: 43.26 time: 9.08\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.99 %\n",
            "Average loss on the 10000 test images: 1.543\n",
            "[17,   100] loss: 1.582 acc: 42.85 time: 7.68\n",
            "[17,   200] loss: 1.579 acc: 43.49 time: 9.00\n",
            "[17,   300] loss: 1.581 acc: 43.03 time: 8.47\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.97 %\n",
            "Average loss on the 10000 test images: 1.539\n",
            "[18,   100] loss: 1.557 acc: 44.48 time: 8.66\n",
            "[18,   200] loss: 1.560 acc: 44.45 time: 8.83\n",
            "[18,   300] loss: 1.578 acc: 43.33 time: 7.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.53 %\n",
            "Average loss on the 10000 test images: 1.534\n",
            "[19,   100] loss: 1.561 acc: 43.88 time: 9.27\n",
            "[19,   200] loss: 1.563 acc: 43.91 time: 8.48\n",
            "[19,   300] loss: 1.578 acc: 43.44 time: 8.25\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.44 %\n",
            "Average loss on the 10000 test images: 1.535\n",
            "[20,   100] loss: 1.550 acc: 44.60 time: 10.65\n",
            "[20,   200] loss: 1.566 acc: 43.70 time: 8.03\n",
            "[20,   300] loss: 1.567 acc: 44.30 time: 9.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.90 %\n",
            "Average loss on the 10000 test images: 1.525\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcN54tcNN15U"
      },
      "source": [
        "##Supervised training on the pre-trained model\n",
        "In this section, we will load the pre-trained ResNet18 model and re-train the whole model on the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xR9h_S1N6Xi",
        "outputId": "334b77bb-cf23-4cc8-cbd1-e0465b393af0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# TODO: Load the pre-trained ResNet18 model\n",
        "model_path = 'my_model.pt'\n",
        "net = resnet18()\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 4)\n",
        "net.load_state_dict(torch.load(model_path))\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 10)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGozc2cM0ADw"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGWW7gzCz_Bu",
        "outputId": "d5e74f38-406b-4e79-a256-5bb0776cc226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.447 acc: 46.90 time: 10.91\n",
            "[1,   200] loss: 1.133 acc: 59.85 time: 8.02\n",
            "[1,   300] loss: 1.037 acc: 63.55 time: 9.68\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.71 %\n",
            "Average loss on the 10000 test images: 0.922\n",
            "[2,   100] loss: 0.916 acc: 67.97 time: 8.63\n",
            "[2,   200] loss: 0.913 acc: 67.68 time: 9.52\n",
            "[2,   300] loss: 0.879 acc: 69.29 time: 9.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.24 %\n",
            "Average loss on the 10000 test images: 0.799\n",
            "[3,   100] loss: 0.797 acc: 72.19 time: 8.11\n",
            "[3,   200] loss: 0.790 acc: 72.26 time: 9.71\n",
            "[3,   300] loss: 0.792 acc: 72.42 time: 9.80\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.80 %\n",
            "Average loss on the 10000 test images: 0.794\n",
            "[4,   100] loss: 0.748 acc: 73.93 time: 8.09\n",
            "[4,   200] loss: 0.736 acc: 74.45 time: 9.68\n",
            "[4,   300] loss: 0.713 acc: 75.41 time: 8.93\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.20 %\n",
            "Average loss on the 10000 test images: 0.758\n",
            "[5,   100] loss: 0.690 acc: 76.12 time: 9.45\n",
            "[5,   200] loss: 0.672 acc: 76.85 time: 9.70\n",
            "[5,   300] loss: 0.683 acc: 76.40 time: 7.95\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.22 %\n",
            "Average loss on the 10000 test images: 0.680\n",
            "[6,   100] loss: 0.664 acc: 76.78 time: 9.78\n",
            "[6,   200] loss: 0.637 acc: 77.92 time: 8.25\n",
            "[6,   300] loss: 0.651 acc: 77.97 time: 9.07\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.01 %\n",
            "Average loss on the 10000 test images: 0.712\n",
            "[7,   100] loss: 0.616 acc: 78.96 time: 9.56\n",
            "[7,   200] loss: 0.624 acc: 78.56 time: 7.95\n",
            "[7,   300] loss: 0.618 acc: 78.34 time: 9.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.78 %\n",
            "Average loss on the 10000 test images: 0.633\n",
            "[8,   100] loss: 0.565 acc: 80.62 time: 8.77\n",
            "[8,   200] loss: 0.591 acc: 79.64 time: 8.90\n",
            "[8,   300] loss: 0.602 acc: 78.83 time: 9.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.78 %\n",
            "Average loss on the 10000 test images: 0.591\n",
            "[9,   100] loss: 0.546 acc: 81.02 time: 7.95\n",
            "[9,   200] loss: 0.571 acc: 80.32 time: 9.52\n",
            "[9,   300] loss: 0.580 acc: 79.91 time: 8.32\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.74 %\n",
            "Average loss on the 10000 test images: 0.602\n",
            "[10,   100] loss: 0.544 acc: 81.23 time: 9.80\n",
            "[10,   200] loss: 0.558 acc: 80.40 time: 9.74\n",
            "[10,   300] loss: 0.549 acc: 80.95 time: 9.17\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.83 %\n",
            "Average loss on the 10000 test images: 0.625\n",
            "[11,   100] loss: 0.479 acc: 83.22 time: 9.82\n",
            "[11,   200] loss: 0.446 acc: 85.03 time: 8.10\n",
            "[11,   300] loss: 0.433 acc: 84.79 time: 9.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.68 %\n",
            "Average loss on the 10000 test images: 0.515\n",
            "[12,   100] loss: 0.427 acc: 85.09 time: 9.38\n",
            "[12,   200] loss: 0.414 acc: 85.74 time: 8.22\n",
            "[12,   300] loss: 0.422 acc: 85.59 time: 9.63\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.83 %\n",
            "Average loss on the 10000 test images: 0.507\n",
            "[13,   100] loss: 0.406 acc: 85.94 time: 8.09\n",
            "[13,   200] loss: 0.398 acc: 86.20 time: 9.61\n",
            "[13,   300] loss: 0.407 acc: 85.97 time: 9.56\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.29 %\n",
            "Average loss on the 10000 test images: 0.498\n",
            "[14,   100] loss: 0.396 acc: 86.12 time: 8.90\n",
            "[14,   200] loss: 0.408 acc: 85.90 time: 9.49\n",
            "[14,   300] loss: 0.400 acc: 86.25 time: 7.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.31 %\n",
            "Average loss on the 10000 test images: 0.498\n",
            "[15,   100] loss: 0.388 acc: 86.49 time: 10.86\n",
            "[15,   200] loss: 0.381 acc: 86.62 time: 9.68\n",
            "[15,   300] loss: 0.399 acc: 86.34 time: 9.18\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.35 %\n",
            "Average loss on the 10000 test images: 0.494\n",
            "[16,   100] loss: 0.384 acc: 86.55 time: 9.52\n",
            "[16,   200] loss: 0.377 acc: 86.81 time: 9.67\n",
            "[16,   300] loss: 0.378 acc: 86.68 time: 8.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.83 %\n",
            "Average loss on the 10000 test images: 0.489\n",
            "[17,   100] loss: 0.377 acc: 87.07 time: 10.16\n",
            "[17,   200] loss: 0.372 acc: 86.54 time: 9.77\n",
            "[17,   300] loss: 0.368 acc: 87.17 time: 8.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.74 %\n",
            "Average loss on the 10000 test images: 0.486\n",
            "[18,   100] loss: 0.368 acc: 87.37 time: 9.72\n",
            "[18,   200] loss: 0.372 acc: 86.77 time: 9.26\n",
            "[18,   300] loss: 0.366 acc: 87.21 time: 8.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.75 %\n",
            "Average loss on the 10000 test images: 0.494\n",
            "[19,   100] loss: 0.364 acc: 87.01 time: 9.72\n",
            "[19,   200] loss: 0.360 acc: 88.02 time: 7.90\n",
            "[19,   300] loss: 0.363 acc: 87.60 time: 9.35\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.54 %\n",
            "Average loss on the 10000 test images: 0.490\n",
            "[20,   100] loss: 0.349 acc: 87.91 time: 8.78\n",
            "[20,   200] loss: 0.363 acc: 87.38 time: 8.99\n",
            "[20,   300] loss: 0.368 acc: 87.17 time: 9.68\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 83.46 %\n",
            "Average loss on the 10000 test images: 0.491\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjVTp9jhefTi"
      },
      "source": [
        "##Supervised training on the randomly initialized model\n",
        "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEjy8TBieeLK",
        "outputId": "42d50992-5d5a-4fb5-95ff-5d8f22366fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# TODO: Randomly initialize a ResNet18 model\n",
        "net = resnet18(pretrained=False)\n",
        "num_classes = 10\n",
        "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEY90pK_0ZAm"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMDwelhY0auO",
        "outputId": "8e0458cb-7adb-4b9e-97f3-1658acc818bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.218 acc: 22.89 time: 9.72\n",
            "[1,   200] loss: 1.822 acc: 33.14 time: 9.44\n",
            "[1,   300] loss: 1.693 acc: 38.02 time: 7.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.71 %\n",
            "Average loss on the 10000 test images: 1.496\n",
            "[2,   100] loss: 1.518 acc: 44.62 time: 9.82\n",
            "[2,   200] loss: 1.443 acc: 47.85 time: 8.09\n",
            "[2,   300] loss: 1.352 acc: 51.12 time: 9.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 54.85 %\n",
            "Average loss on the 10000 test images: 1.278\n",
            "[3,   100] loss: 1.246 acc: 54.81 time: 8.97\n",
            "[3,   200] loss: 1.210 acc: 56.23 time: 8.73\n",
            "[3,   300] loss: 1.163 acc: 58.58 time: 9.49\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 60.91 %\n",
            "Average loss on the 10000 test images: 1.102\n",
            "[4,   100] loss: 1.096 acc: 60.80 time: 8.21\n",
            "[4,   200] loss: 1.064 acc: 61.85 time: 9.65\n",
            "[4,   300] loss: 1.082 acc: 61.95 time: 9.55\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.93 %\n",
            "Average loss on the 10000 test images: 1.036\n",
            "[5,   100] loss: 0.957 acc: 66.16 time: 8.80\n",
            "[5,   200] loss: 0.947 acc: 66.29 time: 9.75\n",
            "[5,   300] loss: 0.948 acc: 67.00 time: 7.91\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.65 %\n",
            "Average loss on the 10000 test images: 0.909\n",
            "[6,   100] loss: 0.883 acc: 68.88 time: 9.81\n",
            "[6,   200] loss: 0.877 acc: 69.24 time: 8.59\n",
            "[6,   300] loss: 0.866 acc: 69.22 time: 8.78\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.83 %\n",
            "Average loss on the 10000 test images: 0.837\n",
            "[7,   100] loss: 0.807 acc: 71.66 time: 9.70\n",
            "[7,   200] loss: 0.816 acc: 71.30 time: 7.64\n",
            "[7,   300] loss: 0.826 acc: 71.05 time: 9.65\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.82 %\n",
            "Average loss on the 10000 test images: 0.790\n",
            "[8,   100] loss: 0.769 acc: 73.14 time: 8.26\n",
            "[8,   200] loss: 0.765 acc: 73.69 time: 9.15\n",
            "[8,   300] loss: 0.752 acc: 74.18 time: 9.34\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 73.21 %\n",
            "Average loss on the 10000 test images: 0.766\n",
            "[9,   100] loss: 0.733 acc: 74.41 time: 8.06\n",
            "[9,   200] loss: 0.729 acc: 74.51 time: 10.53\n",
            "[9,   300] loss: 0.719 acc: 75.00 time: 10.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.89 %\n",
            "Average loss on the 10000 test images: 0.727\n",
            "[10,   100] loss: 0.683 acc: 75.99 time: 8.71\n",
            "[10,   200] loss: 0.703 acc: 75.58 time: 9.59\n",
            "[10,   300] loss: 0.674 acc: 76.73 time: 7.80\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.81 %\n",
            "Average loss on the 10000 test images: 0.702\n",
            "[11,   100] loss: 0.595 acc: 79.09 time: 9.59\n",
            "[11,   200] loss: 0.555 acc: 80.70 time: 8.95\n",
            "[11,   300] loss: 0.541 acc: 81.27 time: 8.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.84 %\n",
            "Average loss on the 10000 test images: 0.556\n",
            "[12,   100] loss: 0.515 acc: 82.23 time: 9.53\n",
            "[12,   200] loss: 0.519 acc: 81.69 time: 7.99\n",
            "[12,   300] loss: 0.511 acc: 82.03 time: 9.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.04 %\n",
            "Average loss on the 10000 test images: 0.554\n",
            "[13,   100] loss: 0.498 acc: 82.80 time: 9.00\n",
            "[13,   200] loss: 0.497 acc: 82.79 time: 8.60\n",
            "[13,   300] loss: 0.507 acc: 82.80 time: 9.42\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.58 %\n",
            "Average loss on the 10000 test images: 0.539\n",
            "[14,   100] loss: 0.483 acc: 83.15 time: 7.87\n",
            "[14,   200] loss: 0.477 acc: 83.48 time: 9.52\n",
            "[14,   300] loss: 0.483 acc: 83.52 time: 8.54\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.70 %\n",
            "Average loss on the 10000 test images: 0.532\n",
            "[15,   100] loss: 0.478 acc: 83.23 time: 9.51\n",
            "[15,   200] loss: 0.471 acc: 83.68 time: 9.57\n",
            "[15,   300] loss: 0.482 acc: 83.17 time: 7.61\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.01 %\n",
            "Average loss on the 10000 test images: 0.531\n",
            "[16,   100] loss: 0.453 acc: 84.13 time: 10.49\n",
            "[16,   200] loss: 0.469 acc: 83.38 time: 9.69\n",
            "[16,   300] loss: 0.466 acc: 83.42 time: 8.34\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.98 %\n",
            "Average loss on the 10000 test images: 0.527\n",
            "[17,   100] loss: 0.456 acc: 84.04 time: 9.55\n",
            "[17,   200] loss: 0.444 acc: 84.45 time: 7.60\n",
            "[17,   300] loss: 0.457 acc: 84.03 time: 9.32\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.16 %\n",
            "Average loss on the 10000 test images: 0.523\n",
            "[18,   100] loss: 0.438 acc: 84.89 time: 8.15\n",
            "[18,   200] loss: 0.454 acc: 84.14 time: 9.33\n",
            "[18,   300] loss: 0.433 acc: 84.68 time: 9.43\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.60 %\n",
            "Average loss on the 10000 test images: 0.517\n",
            "[19,   100] loss: 0.431 acc: 84.95 time: 8.28\n",
            "[19,   200] loss: 0.431 acc: 84.77 time: 9.38\n",
            "[19,   300] loss: 0.441 acc: 84.59 time: 8.11\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.71 %\n",
            "Average loss on the 10000 test images: 0.515\n",
            "[20,   100] loss: 0.421 acc: 85.08 time: 9.59\n",
            "[20,   200] loss: 0.423 acc: 85.16 time: 8.89\n",
            "[20,   300] loss: 0.427 acc: 84.53 time: 8.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 82.36 %\n",
            "Average loss on the 10000 test images: 0.521\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}